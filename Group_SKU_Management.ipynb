{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fa0501e40e94ae8b516649efcd007e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8dbc7589700479e9834c3167e7d3c9e",
              "IPY_MODEL_de2815ef3383461cbd6519126f61b37a",
              "IPY_MODEL_3d7885409a3241998eee96e0b05b29ee"
            ],
            "layout": "IPY_MODEL_b718d7e627164864b0bf9697453e47db"
          }
        },
        "d8dbc7589700479e9834c3167e7d3c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ea987c774514c3da45f4659e5161d82",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d3b58bf716c45a6bbea0601049a7d7e",
            "value": "Batches:â€‡100%"
          }
        },
        "de2815ef3383461cbd6519126f61b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31767b4b23a648c486aed48045edc700",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07c095c21b68469f9621599d07b0cb6f",
            "value": 7
          }
        },
        "3d7885409a3241998eee96e0b05b29ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119d3f7ab7ed44c18d558ed37f1f582f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_367c6efd99a5461f8af12d245bac0807",
            "value": "â€‡7/7â€‡[00:30&lt;00:00,â€‡â€‡2.84s/it]"
          }
        },
        "b718d7e627164864b0bf9697453e47db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea987c774514c3da45f4659e5161d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3b58bf716c45a6bbea0601049a7d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31767b4b23a648c486aed48045edc700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c095c21b68469f9621599d07b0cb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "119d3f7ab7ed44c18d558ed37f1f582f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367c6efd99a5461f8af12d245bac0807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a04cd5d"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "nvidia_api_key = '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'\n",
        "os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key\n",
        "if os.environ[\"NVIDIA_API_KEY\"] == \"\":\n",
        "    print(\"Please check your API\")"
      ],
      "metadata": {
        "id": "I9zokT38RvYz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8pp_OKH8zEGE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import DBSCAN, HDBSCAN\n",
        "import os\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import faiss\n",
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "class ProductVectorManager:\n",
        "    \"\"\"\n",
        "    Optimized manager for product vectors with batch clustering and FAISS retrieval.\n",
        "    Supports:\n",
        "    - DBSCAN/HDBSCAN for offline grouping\n",
        "    - FAISS for fast online nearest neighbor (NN) lookup\n",
        "    - Incremental updates via buffer\n",
        "    - RAG prompt generation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 embed_model_name: str,\n",
        "                 eps_value: float = 0.2,\n",
        "                 min_samples: int = 2,\n",
        "                 use_hdbscan: bool = True,\n",
        "                 similarity_threshold: float = 0.8):\n",
        "        \"\"\"\n",
        "        Initializes the manager.\n",
        "\n",
        "        Args:\n",
        "            embed_model_name (str): S-BERT model name (e.g., 'paraphrase-multilingual-MiniLM-L12-v2')\n",
        "            eps_value (float): Epsilon threshold for DBSCAN (if used)\n",
        "            min_samples (int): Minimum samples (for DBSCAN / min_cluster_size for HDBSCAN)\n",
        "            use_hdbscan (bool): True to use HDBSCAN (recommended), False for DBSCAN\n",
        "            similarity_threshold (float): Similarity threshold (0.0 -> 1.0) for real-time assignment\n",
        "        \"\"\"\n",
        "        self.embed_model_name = embed_model_name\n",
        "        self.eps_value = eps_value\n",
        "        self.min_samples = min_samples\n",
        "        self.use_hdbscan = use_hdbscan\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "\n",
        "        self.model: Optional[SentenceTransformer] = None\n",
        "        self.index: Optional[faiss.Index] = None\n",
        "        self.df: Optional[pd.DataFrame] = None\n",
        "        self.embeddings: Optional[np.ndarray] = None\n",
        "\n",
        "        self._product_buffer: List[Tuple[pd.Series, np.ndarray]] = []\n",
        "\n",
        "        self._load_model()\n",
        "\n",
        "    # ----------------- MODEL -----------------\n",
        "    def _load_model(self):\n",
        "        print(f\"Loading S-BERT model: {self.embed_model_name}...\")\n",
        "        self.model = SentenceTransformer(self.embed_model_name)\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    # ----------------- DATA PREP -----------------\n",
        "    def _read_json(self, json_file: str) -> dict:\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def _flatten_attributes(self, attr_products: Optional[dict]) -> dict:\n",
        "        if not attr_products or 'data' not in attr_products:\n",
        "            return {}\n",
        "        result = {}\n",
        "        for a in attr_products.get('data', []):\n",
        "            key = a.get('attributes', {}).get('name') or f\"attr_{a.get('attribute_id')}\"\n",
        "            value = a.get('attribute_values', {}).get('name') if a.get('attribute_values') else None\n",
        "            if key and value:\n",
        "                result[key] = value\n",
        "        return result\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        if text is None:\n",
        "            return \"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^\\w\\s]\", \" \", text) # remove punctuation\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip() # remove extra whitespace\n",
        "        return text\n",
        "\n",
        "    def _transform_data_from_json(self, json_file: str) -> pd.DataFrame:\n",
        "        products = self._read_json(json_file)['data']\n",
        "        result_list = []\n",
        "\n",
        "        for product in products:\n",
        "            skus = product.get('product_skus', {}).get('data', [])\n",
        "            sku_detail = skus[0].get('product_sku_detail', {}) if skus else {}\n",
        "\n",
        "            product_info = {\n",
        "                \"product_id\": product.get(\"id\"),\n",
        "                \"product_name\": product.get(\"name\"),\n",
        "                \"brand_name\": product.get(\"brand\", {}).get(\"name\"),\n",
        "                \"platform_name\": product.get(\"shop\", {}).get(\"platform_name\"),\n",
        "                \"shop_country\": product.get(\"shop\", {}).get(\"country\"),\n",
        "                \"short_description\": product.get(\"short_description\"),\n",
        "                \"price\": sku_detail.get(\"price\"),\n",
        "                \"quantity\": sku_detail.get(\"quantity\", 0),\n",
        "                \"attribute_products\": {\n",
        "                    \"data\": self._flatten_attributes(product.get(\"attribute_products\"))\n",
        "                },\n",
        "            }\n",
        "            result_list.append(product_info)\n",
        "        return pd.DataFrame(result_list)\n",
        "\n",
        "    #Can custome\n",
        "    def _get_text_for_embedding(self, product_row: pd.Series) -> str:\n",
        "        name = self._clean_text(product_row.get('product_name', ''))\n",
        "        desc = self._clean_text(product_row.get('short_description', ''))\n",
        "        brand = self._clean_text(product_row.get('brand_name', ''))\n",
        "\n",
        "        natural_text = f\"{name} by {brand}. {desc}\"\n",
        "\n",
        "        keyword_set = set()\n",
        "        if name: keyword_set.add(name)\n",
        "        if brand: keyword_set.add(brand)\n",
        "        attributes_data = product_row.get('attribute_products', {}).get('data', {})\n",
        "        if isinstance(attributes_data, dict):\n",
        "            for key, value in attributes_data.items():\n",
        "                if value:\n",
        "                    keyword_set.add(self._clean_text(str(value)))\n",
        "\n",
        "        keyword_text = \" | \".join(sorted(list(keyword_set)))\n",
        "        return f\"Product: {natural_text}\\nKeywords: {keyword_text}\"\n",
        "\n",
        "    # ----------------- BATCH BUILD -----------------\n",
        "    def build_from_json(self, json_file: str):\n",
        "        print(f\"Building from {json_file}...\")\n",
        "        self.df = self._transform_data_from_json(json_file)\n",
        "        texts = self.df.apply(self._get_text_for_embedding, axis=1).tolist()\n",
        "\n",
        "        # Encode in batches and ensure float32\n",
        "        self.embeddings = embeddings = self.model.encode(\n",
        "            texts,\n",
        "            show_progress_bar=True,\n",
        "            batch_size=64\n",
        "        ).astype('float32')\n",
        "\n",
        "        faiss.normalize_L2(embeddings)  # Normalize for Cosine/IP\n",
        "\n",
        "        # ----------- CLUSTERING -----------\n",
        "        if self.use_hdbscan:\n",
        "            print(\"Using HDBSCAN for clustering...\")\n",
        "            clusterer = HDBSCAN(\n",
        "                min_cluster_size=self.min_samples,\n",
        "                metric='cosine'\n",
        "            )\n",
        "            clusters = clusterer.fit_predict(embeddings)\n",
        "        else:\n",
        "            print(\"Using DBSCAN for clustering...\")\n",
        "            dbscan = DBSCAN(\n",
        "                eps=self.eps_value,\n",
        "                min_samples=self.min_samples,\n",
        "                metric='cosine'\n",
        "            )\n",
        "            clusters = dbscan.fit_predict(embeddings)\n",
        "\n",
        "        self.df['group_sku_id'] = clusters\n",
        "        self.df.to_csv('result.csv', index=False)\n",
        "\n",
        "        # ----------- BUILD FAISS INDEX -----------\n",
        "        d = embeddings.shape[1]\n",
        "        nlist = int(self.df['group_sku_id'].max() + 1)\n",
        "        print(f\"Building FAISS IndexIVFFlat with nlist={nlist}...\")\n",
        "\n",
        "        quantizer = faiss.IndexFlatIP(d)  # coarse quantizer for IVF\n",
        "        self.index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "        # Train before adding\n",
        "        if not self.index.is_trained:\n",
        "            print(\"Training FAISS index (coarse quantizer)...\")\n",
        "            self.index.train(embeddings)\n",
        "            print(\"Training complete.\")\n",
        "\n",
        "        # Add all embeddings to IVF index\n",
        "        self.index.add(embeddings)\n",
        "\n",
        "        # Config search behavior\n",
        "        self.index.nprobe = min(10, nlist)  # search in up to 10 clusters\n",
        "        print(f\"FAISS IVF Index built with {self.index.ntotal} vectors (nprobe={self.index.nprobe}).\")\n",
        "\n",
        "\n",
        "    # ----------------- CHECK -----------------\n",
        "    def _check_ready(self):\n",
        "        if self.index is None or self.df is None or self.model is None:\n",
        "            raise Exception(\"Manager not ready. Run build_from_json() first.\")\n",
        "\n",
        "    # ----------------- ASSIGN NEW PRODUCT -----------------\n",
        "    def assign_new_product(self, product_dict: Dict[str, Any]) -> int:\n",
        "        \"\"\"\n",
        "        Assigns a Group SKU ID to a new product and adds it to the buffer.\n",
        "        Flushes the buffer to the main index when it's full.\n",
        "        \"\"\"\n",
        "        self._check_ready()\n",
        "        new_series = pd.Series(product_dict)\n",
        "        new_text = self._get_text_for_embedding(new_series)\n",
        "\n",
        "        # Minor tweak: ensure encode output is float32\n",
        "        new_vector = self.model.encode([new_text]).astype('float32')\n",
        "        faiss.normalize_L2(new_vector)\n",
        "\n",
        "        # Search FAISS\n",
        "        D, I = self.index.search(new_vector, k=1)\n",
        "        nearest_index = I[0][0]\n",
        "        similarity = D[0][0]\n",
        "\n",
        "        if similarity >= self.similarity_threshold:\n",
        "            new_group_id = self.df.loc[nearest_index, 'group_sku_id']\n",
        "        else:\n",
        "            new_group_id = -1  # outlier\n",
        "\n",
        "        new_series['group_sku_id'] = new_group_id\n",
        "\n",
        "        # Batch update FAISS for performance\n",
        "        self._product_buffer.append((new_series, new_vector))\n",
        "        if len(self._product_buffer) >= 50:  # Buffer flush threshold\n",
        "            print(f\"Flushing {len(self._product_buffer)} products from buffer to index...\")\n",
        "            series_to_add = [item[0] for item in self._product_buffer]\n",
        "            vectors_to_add = np.vstack([item[1] for item in self._product_buffer])\n",
        "\n",
        "            # Add to FAISS (no re-encoding)\n",
        "            self.index.add(vectors_to_add)\n",
        "\n",
        "            # Add to DataFrame\n",
        "            self.df = pd.concat([self.df, pd.DataFrame(series_to_add)], ignore_index=True)\n",
        "\n",
        "            # Clear buffer\n",
        "            self._product_buffer = []\n",
        "\n",
        "        return int(new_group_id)\n",
        "\n",
        "    def flush_buffer(self):\n",
        "        \"\"\"\n",
        "        Manually flushes any remaining products in the buffer.\n",
        "        Should be called before application shutdown.\n",
        "        \"\"\"\n",
        "        if not self._product_buffer:\n",
        "            print(\"Buffer is empty, no flush needed.\")\n",
        "            return\n",
        "\n",
        "        print(f\"Flushing {len(self._product_buffer)} remaining products from buffer...\")\n",
        "        series_to_add = [item[0] for item in self._product_buffer]\n",
        "        vectors_to_add = np.vstack([item[1] for item in self._product_buffer])\n",
        "\n",
        "        self.index.add(vectors_to_add)\n",
        "        self.df = pd.concat([self.df, pd.DataFrame(series_to_add)], ignore_index=True)\n",
        "        self._product_buffer = []\n",
        "        print(\"Buffer flush complete.\")\n",
        "\n",
        "    # ----------------- RAG PROMPT -----------------\n",
        "    def generate_rag_prompt(self, user_question: str, k: int = 5) -> str:\n",
        "        self._check_ready()\n",
        "\n",
        "        PROMPT_TEMPLATE = \"\"\"\n",
        "Based on the following context:\n",
        "\n",
        "--- Context ---\n",
        "{context}\n",
        "--- End Context ---\n",
        "\n",
        "Please answer the user's question in a friendly manner, using only the information from the context.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Your Answer:\n",
        "\"\"\"\n",
        "        question_vector = self.model.encode([user_question]).astype('float32')\n",
        "        faiss.normalize_L2(question_vector)\n",
        "\n",
        "        D, I = self.index.search(question_vector, k=k)\n",
        "        context_strings = []\n",
        "        for idx in I[0]:\n",
        "            if idx < 0: continue # FAISS can return -1 if index is empty/small\n",
        "            product_row = self.df.iloc[idx]\n",
        "            context_strings.append(self._get_text_for_embedding(product_row))\n",
        "\n",
        "        context = \"\\n\".join([f\"- Related Product: {txt}\" for txt in context_strings])\n",
        "        prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE).format(\n",
        "            context=context,\n",
        "            question=user_question\n",
        "        )\n",
        "        return context, prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4HaI71K_PAO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_MODEL = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
        "EPS_VALUE = 0.023 # The value you found from your k-distance plot\n",
        "MIN_SAMPLES = 2\n",
        "\n",
        "manager = ProductVectorManager(\n",
        "    embed_model_name=EMBED_MODEL,\n",
        "    eps_value=EPS_VALUE,\n",
        "    min_samples=MIN_SAMPLES,\n",
        "    use_hdbscan=True\n",
        ")\n",
        "manager.build_from_json('/content/exampel.json')\n",
        "\n",
        "#ADD NEW Product\n",
        "new_product_data = {\n",
        "    'product_id': 541187,\n",
        "    'product_name': 'Omni Item (Ä‘á»)',\n",
        "    'brand_name': 'No Brand',\n",
        "    'platform_name': 'Preny Test',\n",
        "    'shop_country': 'vn',\n",
        "    'short_description': None,\n",
        "    'price': 1000000,\n",
        "    'quantity': 111106,\n",
        "    'attribute_products': {'data': {'brand': 'No Brand',\n",
        "    'warranty_type': 'Warranty Paper and Invoice',\n",
        "    'is_hazardous': 'None'}}\n",
        "}\n",
        "\n",
        "try:\n",
        "    assigned_id = manager.assign_new_product(new_product_data)\n",
        "    print(f\"Result:\\nNew product has been assigned Group SKU ID: {assigned_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "1fa0501e40e94ae8b516649efcd007e9",
            "d8dbc7589700479e9834c3167e7d3c9e",
            "de2815ef3383461cbd6519126f61b37a",
            "3d7885409a3241998eee96e0b05b29ee",
            "b718d7e627164864b0bf9697453e47db",
            "0ea987c774514c3da45f4659e5161d82",
            "8d3b58bf716c45a6bbea0601049a7d7e",
            "31767b4b23a648c486aed48045edc700",
            "07c095c21b68469f9621599d07b0cb6f",
            "119d3f7ab7ed44c18d558ed37f1f582f",
            "367c6efd99a5461f8af12d245bac0807"
          ]
        },
        "id": "TltqNNFvNia8",
        "outputId": "973097fd-e378-4a95-8809-2fa5ca1db5a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading S-BERT model: paraphrase-multilingual-MiniLM-L12-v2...\n",
            "Model loaded successfully.\n",
            "Building from /content/exampel.json...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa0501e40e94ae8b516649efcd007e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using HDBSCAN for clustering...\n",
            "Building FAISS IndexIVFFlat with nlist=102...\n",
            "Training FAISS index (coarse quantizer)...\n",
            "Training complete.\n",
            "FAISS IVF Index built with 400 vectors (nprobe=10).\n",
            "Result:\n",
            "New product has been assigned Group SKU ID: 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAG\n",
        "LLM_MODEL = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
        "\n",
        "question = \"Do you have any Iphone, I want to advise about Iphone?\"\n",
        "try:\n",
        "    contex, prompt = manager.generate_rag_prompt(question, k=5)\n",
        "    llm = ChatNVIDIA(model=LLM_MODEL)\n",
        "    response = llm.invoke(prompt)\n",
        "    print(\"\\nAnswer:\")\n",
        "    print(response.content if hasattr(response, \"content\") else response)\n",
        "    print(\"\\nSources:\")\n",
        "    print(contex)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJaaB7MBPL5J",
        "outputId": "49e10702-e838-48e9-9c2a-b81e78a5da3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer:\n",
            "Yes, we have several iPhone 17 models available based on your query! For example:  \n",
            "- **iPhone 17 512GB (standard)**  \n",
            "- **iPhone 17 Air 512GB**  \n",
            "- **iPhone 17 Pro 512GB**  \n",
            "\n",
            "All these are OEM products. Could you let me know which specific model or feature you're interested in? Iâ€™d be happy to provide more details or advice! ðŸ˜Š\n",
            "\n",
            "Sources:\n",
            "- Related Product: Product: á»‘p lÆ°ng Ä‘iá»‡n thoáº¡i iphone 17 512gb by oem. \n",
            "Keywords: invoice | none | oem | phone | á»‘p lÆ°ng Ä‘iá»‡n thoáº¡i iphone 17 512gb\n",
            "- Related Product: Product: á»‘p lÆ°ng iphone 17 air 512gb by oem. \n",
            "Keywords: none | oem | á»‘p lÆ°ng iphone 17 air 512gb\n",
            "- Related Product: Product: á»‘p lÆ°ng iphone 17 pro 512gb by oem. \n",
            "Keywords: none | oem | á»‘p lÆ°ng iphone 17 pro 512gb\n",
            "- Related Product: Product: phá»¥ kiá»‡n ipad pro m4 11 inch wifi 256gb by oem. \n",
            "Keywords: invoice | none | oem | phá»¥ kiá»‡n ipad pro m4 11 inch wifi 256gb\n",
            "- Related Product: Product: Ä‘iá»‡n thoáº¡i 11111111111111111111 by no brand. \n",
            "Keywords: no brand | Ä‘iá»‡n thoáº¡i 11111111111111111111\n"
          ]
        }
      ]
    }
  ]
}